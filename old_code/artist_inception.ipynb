{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPALt2OrrDSXBoiDI9TGHmX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t_yOBIqdBPgE","executionInfo":{"status":"ok","timestamp":1670709425359,"user_tz":480,"elapsed":29066,"user":{"displayName":"Finn","userId":"01146107018286362364"}},"outputId":"6427d45a-34ba-49c5-a508-96ceb5111c54"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","# inspired by https://stackoverflow.com/questions/7391945/how-do-i-read-image-data-from-a-url-in-python\n","from PIL import Image\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import os\n","from google.colab import drive\n","from tensorflow.keras.applications.inception_v3 import InceptionV3\n","\n","\n","drive.mount('/content/drive')\n","# Set the random seed\n","np.random.seed(1337)"]},{"cell_type":"code","source":["%cd drive/MyDrive/Year_5/ML-Artwork/data/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DZLFlkaiBUTc","executionInfo":{"status":"ok","timestamp":1670709425594,"user_tz":480,"elapsed":238,"user":{"displayName":"Finn","userId":"01146107018286362364"}},"outputId":"228a260c-b842-4bf5-803a-7d98e7393ac4"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Year_5/ML-Artwork/data\n"]}]},{"cell_type":"code","source":["(img_x, img_y) = (150, 150)\n","image_size=(img_x, img_y)\n","train_ds = keras.preprocessing.image_dataset_from_directory(\n","  \"paintings_450\",\n","  label_mode = \"categorical\",\n","  validation_split=0.3,\n","  subset=\"training\",\n","  seed=1337,\n","  image_size=image_size,\n","  batch_size=20)\n","\n","val_ds = keras.preprocessing.image_dataset_from_directory(\n","  \"paintings_450\",\n","  label_mode = \"categorical\",\n","  validation_split=0.3,\n","  subset=\"validation\",\n","  seed=1337,\n","  image_size=image_size,\n","  batch_size=20)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yL4dNrXpBWeG","executionInfo":{"status":"ok","timestamp":1670713255475,"user_tz":480,"elapsed":2328,"user":{"displayName":"Finn","userId":"01146107018286362364"}},"outputId":"8e9930a3-7ddd-4535-cd8a-abe04ddec8d3"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 4411 files belonging to 10 classes.\n","Using 3088 files for training.\n","Found 4411 files belonging to 10 classes.\n","Using 1323 files for validation.\n"]}]},{"cell_type":"code","source":["# we apply random horizontal flipping or small random rotations to augment the dataset since we only have 450 images.\n","# \n","# data_augmentation = keras.Sequential(\n","#     [\n","#         layers.RandomFlip(\"horizontal\"),\n","#         layers.RandomRotation(0.15),\n","#     ]\n","# )\n","\n","# Apply `data_augmentation` to the training images.\n","# train_ds = train_ds.map(\n","#     lambda img, label: (data_augmentation(img), label),\n","#     num_parallel_calls=tf.data.AUTOTUNE,\n","# )\n","# Prefetching samples in GPU memory helps maximize GPU utilization.\n","train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n","val_ds = val_ds.prefetch(tf.data.AUTOTUNE)"],"metadata":{"id":"ud_jIHerBZBd","executionInfo":{"status":"ok","timestamp":1670713263859,"user_tz":480,"elapsed":146,"user":{"displayName":"Finn","userId":"01146107018286362364"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# help from https://www.analyticsvidhya.com/blog/2020/08/top-4-pre-trained-models-for-image-classification-with-python-code/#:~:text=Pre-Trained%20Models%20for%20Image%20Classification%201%201.%20Very,first%20model%20coming%20from%20the%20ResNet%20family.%20\n","\n","base_model = InceptionV3(input_shape=(img_x,img_y,3),\n","                   include_top=False, weights='imagenet')\n","for layer in base_model.layers:\n","  layer.trainable = False"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m_T0pUd7Bg1L","executionInfo":{"status":"ok","timestamp":1670709438976,"user_tz":480,"elapsed":3525,"user":{"displayName":"Finn","userId":"01146107018286362364"}},"outputId":"ca26f16d-2e29-4d69-90f4-3c73ab8c340d"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n","87910968/87910968 [==============================] - 1s 0us/step\n"]}]},{"cell_type":"code","source":["x = layers.Flatten()(base_model.output)\n","x = layers.Dense(1024, activation='relu')(x)\n","x = layers.Dropout(0.2)(x)\n","x = layers.Dense(10, activation='sigmoid')(x)\n","\n","model = tf.keras.models.Model(base_model.input, x)\n","model.compile(optimizer = tf.keras.optimizers.RMSprop(lr = 0.01),\n","              loss = 'binary_crossentropy', metrics = ['acc'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_cqso5qCBh0C","executionInfo":{"status":"ok","timestamp":1670713269503,"user_tz":480,"elapsed":533,"user":{"displayName":"Finn","userId":"01146107018286362364"}},"outputId":"80173cc7-c0fd-4255-86f8-080af5d4eb83"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(RMSprop, self).__init__(name, **kwargs)\n"]}]},{"cell_type":"code","source":["train_ds = train_ds.repeat()\n","val_ds = val_ds.repeat()"],"metadata":{"id":"NTC2DdvKFYPt","executionInfo":{"status":"ok","timestamp":1670713271253,"user_tz":480,"elapsed":149,"user":{"displayName":"Finn","userId":"01146107018286362364"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["model.fit(train_ds, validation_data=val_ds, steps_per_epoch=100,\n","          epochs=20, validation_steps=50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1k4Njnw9CYBg","executionInfo":{"status":"ok","timestamp":1670716892241,"user_tz":480,"elapsed":3610483,"user":{"displayName":"Finn","userId":"01146107018286362364"}},"outputId":"64006960-47d5-45f0-a627-ffa06c789c70"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","100/100 [==============================] - 231s 2s/step - loss: 357.5312 - acc: 0.1315 - val_loss: 0.6211 - val_acc: 0.1200\n","Epoch 2/20\n","100/100 [==============================] - 171s 2s/step - loss: 17.2092 - acc: 0.1172 - val_loss: 0.3836 - val_acc: 0.1060\n","Epoch 3/20\n","100/100 [==============================] - 173s 2s/step - loss: 0.9946 - acc: 0.1020 - val_loss: 0.3352 - val_acc: 0.1000\n","Epoch 4/20\n","100/100 [==============================] - 180s 2s/step - loss: 2.7587 - acc: 0.1071 - val_loss: 0.3304 - val_acc: 0.0950\n","Epoch 5/20\n","100/100 [==============================] - 176s 2s/step - loss: 2.2070 - acc: 0.0991 - val_loss: 0.3299 - val_acc: 0.1040\n","Epoch 6/20\n","100/100 [==============================] - 177s 2s/step - loss: 0.7965 - acc: 0.1005 - val_loss: 0.3295 - val_acc: 0.0920\n","Epoch 7/20\n","100/100 [==============================] - 178s 2s/step - loss: 0.7026 - acc: 0.0900 - val_loss: 0.3293 - val_acc: 0.0940\n","Epoch 8/20\n","100/100 [==============================] - 177s 2s/step - loss: 0.3366 - acc: 0.0946 - val_loss: 0.3290 - val_acc: 0.1010\n","Epoch 9/20\n","100/100 [==============================] - 176s 2s/step - loss: 0.3699 - acc: 0.1030 - val_loss: 0.3292 - val_acc: 0.0940\n","Epoch 10/20\n","100/100 [==============================] - 175s 2s/step - loss: 0.3402 - acc: 0.0941 - val_loss: 0.3291 - val_acc: 0.1050\n","Epoch 11/20\n","100/100 [==============================] - 181s 2s/step - loss: 0.3295 - acc: 0.1066 - val_loss: 0.3292 - val_acc: 0.1040\n","Epoch 12/20\n","100/100 [==============================] - 174s 2s/step - loss: 0.3251 - acc: 0.1025 - val_loss: 0.3291 - val_acc: 0.0960\n","Epoch 13/20\n","100/100 [==============================] - 174s 2s/step - loss: 0.3251 - acc: 0.1021 - val_loss: 0.3291 - val_acc: 0.1090\n","Epoch 14/20\n","100/100 [==============================] - 180s 2s/step - loss: 0.3252 - acc: 0.0956 - val_loss: 0.3293 - val_acc: 0.1090\n","Epoch 15/20\n","100/100 [==============================] - 176s 2s/step - loss: 0.3287 - acc: 0.1010 - val_loss: 0.3292 - val_acc: 0.0960\n","Epoch 16/20\n","100/100 [==============================] - 173s 2s/step - loss: 0.3252 - acc: 0.1081 - val_loss: 0.3292 - val_acc: 0.1080\n","Epoch 17/20\n","100/100 [==============================] - 177s 2s/step - loss: 0.3252 - acc: 0.1020 - val_loss: 0.3291 - val_acc: 0.0980\n","Epoch 18/20\n","100/100 [==============================] - 189s 2s/step - loss: 0.3252 - acc: 0.0910 - val_loss: 0.3290 - val_acc: 0.0980\n","Epoch 19/20\n","100/100 [==============================] - 177s 2s/step - loss: 0.3252 - acc: 0.1026 - val_loss: 0.3293 - val_acc: 0.1080\n","Epoch 20/20\n","100/100 [==============================] - 180s 2s/step - loss: 0.3252 - acc: 0.1010 - val_loss: 0.3292 - val_acc: 0.0900\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fe0be4d3fd0>"]},"metadata":{},"execution_count":16}]}]}