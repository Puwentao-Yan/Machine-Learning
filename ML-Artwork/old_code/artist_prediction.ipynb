{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"5TNkyKt1r_U5"},"outputs":[],"source":["# Import statements\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.utils import shuffle\n","from PIL import Image\n","import requests\n","from keras.utils import to_categorical\n","from io import BytesIO\n","\n","# Set the random seed\n","np.random.seed(1337)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FFOhctPVsmTw","executionInfo":{"status":"ok","timestamp":1670539373921,"user_tz":480,"elapsed":609,"user":{"displayName":"Tao Vi","userId":"11970432692976070869"}},"outputId":"1c112a03-ad47-4f5a-dce9-f2ed9dc88358"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'Albrecht Durer': 0, 'Alfred Freddy Krupa': 1, 'Claude Monet': 2, 'Giovanni Battista Piranesi': 3, 'Henri Matisse': 4, 'Marc Chagall': 5, 'Pablo Picasso': 6, 'Rembrandt': 7, 'Salvador Dali': 8, 'Vincent van Gogh': 9}\n"]}],"source":["# Define constants for the number of training and testing examples for each artist\n","NUM_TRAIN = 50\n","NUM_TEST = 20\n","\n","# Create a dataframe for the cleaned dataset\n","df = pd.read_csv(\"https://gist.githubusercontent.com/jd1771/4483a72c10b94fb28d4de22ac12d9b80/raw/1abc382362cfac751b3c784563d1afc327371e9b/clean.csv\")\n","\n","# Get a list of the top 10 artist names \n","artist_names = df[\"Artist\"].unique()\n","\n","encoded_dict = {}\n","\n","# Encode the artist values to a dictionary\n","for i in range(len(artist_names)):\n","  encoded_dict[artist_names[i]] = i\n","\n","\n","\n","print(encoded_dict)\n","\n","\n","\n","\n","  \n","\n"]},{"cell_type":"code","source":["# Loop through each artist and add the images to memory\n","\n","artist_paintings = {}\n","\n","for artist in artist_names:\n","\n","  artist_paintings[artist] = []\n","  \n","  # Get the top paintings and an image URL list for each artist\n","  top_paintings = df[df['Artist']==artist].head(NUM_TRAIN + NUM_TEST)\n","  img_list =  top_paintings['Link'].tolist()\n","  \n","  for i in range(len(img_list)):\n","\n","    \n","    # Get the image link\n","    painting_link = img_list[i]\n","\n","    # Get the image content\n","    response = requests.get(painting_link)\n","    img = Image.open(BytesIO(response.content))\n","\n","    # Add the image of the painting to the artist dictionary\n","    artist_paintings[artist].append(img)\n","    "],"metadata":{"id":"rgnktif22a8v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, y_train, X_test, y_test = [] , [], [], []\n","\n","# Apply image transformations and add the paintings to the train/test splits\n","for artist, paintings in artist_paintings.items():\n","    for i in range(len(paintings)):\n","        \n","        img = paintings[i]\n","\n","        # Resize the image\n","        img_resized = img.resize((100,100))\n","\n","        # Convert the image to an numpy array\n","        img_arr = np.array(img_resized)\n","\n","        # In rare cases, the RGB channel is excluded in the \n","        # shape of some images. This will crash the neural network\n","        # if it is not removed. I have only seen 13 examples out of \n","        # 800 where this is the case.\n","        if len(img_arr.shape) != 3 or img_arr.shape[2] != 3:\n","          continue\n","      \n","        # Normalize the image array\n","        img_arr = img_arr.astype('float32')\n","        img_arr /= 255.0\n","\n","        # Append the painting to the training split\n","        if i < NUM_TRAIN:\n","          \n","          X_train.append(img_arr)\n","          y_train.append(artist)\n","\n","        # Append the painting to the test split\n","        else:\n","          \n","          X_test.append(img_arr)\n","          y_test.append(artist)\n","\n","    \n","# Apply 1-k encoding to the label vectors\n","y_train = [encoded_dict[label] for label in y_train]\n","y_train = to_categorical(y_train)\n","y_test = [encoded_dict[label] for label in y_test]\n","y_test = to_categorical(y_test)\n","\n","# Shuffle the data\n","X_train, y_train = shuffle(X_train, y_train)\n","X_test, y_test = shuffle(X_test, y_test)\n","\n","print(len(X_train), len(y_train))\n","print(len(X_test), len(y_test))\n","\n","\n","\n","\n"],"metadata":{"id":"2rCgf06JqHdk","executionInfo":{"status":"ok","timestamp":1670540088949,"user_tz":480,"elapsed":35166,"user":{"displayName":"Tao Vi","userId":"11970432692976070869"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"dc930e2c-d2f1-41b8-9eb3-86bd0aac5d96"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["494 494\n","199 199\n"]}]},{"cell_type":"code","source":["from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n","from keras import regularizers\n","from keras.models import Sequential\n","import keras\n","\n","# Create the CNN model\n","model = Sequential()\n","\n","# Add the layers\n","model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(100,100,3)))\n","model.add(Conv2D(32, kernel_size=3, activation='relu'))\n","model.add(Flatten())\n","model.add(Dense(10, activation='softmax'))\n","\n","# Evaluate the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","model.fit(np.array(X_train), np.array(y_train), validation_data=(np.array(X_test), np.array(y_test)), epochs=10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LZyKsXe60ax_","outputId":"8cfec872-fdbc-4ac1-dd4f-60023ed8a2da","executionInfo":{"status":"ok","timestamp":1670540352089,"user_tz":480,"elapsed":263142,"user":{"displayName":"Tao Vi","userId":"11970432692976070869"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","16/16 [==============================] - 25s 1s/step - loss: 5.8889 - accuracy: 0.1113 - val_loss: 2.2888 - val_accuracy: 0.1307\n","Epoch 2/10\n","16/16 [==============================] - 23s 1s/step - loss: 2.2360 - accuracy: 0.1518 - val_loss: 2.2504 - val_accuracy: 0.1457\n","Epoch 3/10\n","16/16 [==============================] - 23s 1s/step - loss: 1.9974 - accuracy: 0.2834 - val_loss: 2.1447 - val_accuracy: 0.2412\n","Epoch 4/10\n","16/16 [==============================] - 23s 1s/step - loss: 1.4565 - accuracy: 0.5911 - val_loss: 2.2148 - val_accuracy: 0.2563\n","Epoch 5/10\n","16/16 [==============================] - 24s 2s/step - loss: 0.9103 - accuracy: 0.7895 - val_loss: 2.7611 - val_accuracy: 0.2513\n","Epoch 6/10\n","16/16 [==============================] - 26s 2s/step - loss: 0.5106 - accuracy: 0.8806 - val_loss: 2.7296 - val_accuracy: 0.2060\n","Epoch 7/10\n","16/16 [==============================] - 23s 1s/step - loss: 0.3225 - accuracy: 0.9332 - val_loss: 3.1574 - val_accuracy: 0.2563\n","Epoch 8/10\n","16/16 [==============================] - 23s 1s/step - loss: 0.1944 - accuracy: 0.9656 - val_loss: 2.9884 - val_accuracy: 0.2462\n","Epoch 9/10\n","16/16 [==============================] - 23s 1s/step - loss: 0.1077 - accuracy: 0.9798 - val_loss: 3.0921 - val_accuracy: 0.2714\n","Epoch 10/10\n","16/16 [==============================] - 23s 1s/step - loss: 0.0518 - accuracy: 0.9919 - val_loss: 3.2265 - val_accuracy: 0.3367\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f858163edc0>"]},"metadata":{},"execution_count":5}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}