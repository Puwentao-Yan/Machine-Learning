{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E1h1qqspiiyh","executionInfo":{"status":"ok","timestamp":1670717895046,"user_tz":480,"elapsed":1062,"user":{"displayName":"Finn","userId":"01146107018286362364"}},"outputId":"9cc0397c-a9f4-40ed-e582-a31fefa9c295"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","# inspired by https://stackoverflow.com/questions/7391945/how-do-i-read-image-data-from-a-url-in-python\n","from PIL import Image\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import os\n","from google.colab import drive\n","from tensorflow.keras.applications.vgg16 import VGG16\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","\n","drive.mount('/content/drive')\n","# Set the random seed\n","np.random.seed(1337)"]},{"cell_type":"code","source":["%cd drive/MyDrive/Year_5/ML-Artwork/data/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SReTS3yNkC4_","executionInfo":{"status":"ok","timestamp":1670701494688,"user_tz":480,"elapsed":589,"user":{"displayName":"Finn","userId":"01146107018286362364"}},"outputId":"f96a1f03-5a7e-4cf8-9de1-4852b16c9331"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Year_5/ML-Artwork/data\n"]}]},{"cell_type":"code","source":["(img_x,img_y)=(300,300)\n","image_size=(img_x,img_y)\n","train_ds = keras.preprocessing.image_dataset_from_directory(\n","  \"paintings_450\",\n","  label_mode = \"categorical\",\n","  validation_split=0.2,\n","  subset=\"training\",\n","  seed=1337,\n","  image_size=image_size,\n","  batch_size=36)\n","\n","val_ds = keras.preprocessing.image_dataset_from_directory(\n","  \"paintings_450\",\n","  label_mode = \"categorical\",\n","  validation_split=0.2,\n","  subset=\"validation\",\n","  seed=1337,\n","  image_size=image_size,\n","  batch_size=36)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QegsnDJJjQdf","executionInfo":{"status":"ok","timestamp":1670713194076,"user_tz":480,"elapsed":2748,"user":{"displayName":"Finn","userId":"01146107018286362364"}},"outputId":"bb72e2a8-d845-4774-a7b9-eb5692c528fc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 4411 files belonging to 10 classes.\n","Using 3529 files for training.\n","Found 4411 files belonging to 10 classes.\n","Using 882 files for validation.\n"]}]},{"cell_type":"code","source":["train_datagen = ImageDataGenerator(rescale=1./255.,rotation_range=40,\n","                                   width_shift_range=0.2,\n","                                   height_shift_range=0.2, shear_range=0.2,\n","                                   zoom_range=0.2, horizontal_flip = True)\n","test_datagen = ImageDataGenerator(rescale=1./255.)"],"metadata":{"id":"GEHBAHFZQK6W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_ds = train_datagen.flow_from_directory(\"paintings_450\", batch_size=20,\n","                                             class_mode='binary',\n","                                             target_size=(img_x,img_y))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9yrnp85CiXHv","executionInfo":{"status":"ok","timestamp":1670717900866,"user_tz":480,"elapsed":358,"user":{"displayName":"Finn","userId":"01146107018286362364"}},"outputId":"02d48e78-adca-47e4-9c2b-d339883a9faf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 4411 images belonging to 10 classes.\n"]}]},{"cell_type":"code","source":["# we apply random horizontal flipping or small random rotations to augment the dataset since we only have 450 images.\n","# \n","data_augmentation = keras.Sequential(\n","    [\n","        layers.RandomFlip(\"horizontal\"),\n","        layers.RandomRotation(0.15),\n","    ]\n",")"],"metadata":{"id":"2KcFzGrajc6k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Apply `data_augmentation` to the training images.\n","# train_ds = train_ds.map(\n","#     lambda img, label: (data_augmentation(img), label),\n","#     num_parallel_calls=tf.data.AUTOTUNE,\n","# )\n","# Prefetching samples in GPU memory helps maximize GPU utilization.\n","train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n","val_ds = val_ds.prefetch(tf.data.AUTOTUNE)"],"metadata":{"id":"FugzIYX_jk1w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# help from https://www.analyticsvidhya.com/blog/2020/08/top-4-pre-trained-models-for-image-classification-with-python-code/#:~:text=Pre-Trained%20Models%20for%20Image%20Classification%201%201.%20Very,first%20model%20coming%20from%20the%20ResNet%20family.%20\n","\n","base_model = VGG16(input_shape=(img_x,img_y,3),\n","                   include_top=False, weights='imagenet')\n","for layer in base_model.layers:\n","  layer.trainable = False"],"metadata":{"id":"AIpI9gzRmfgM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = layers.Flatten()(base_model.output)\n","x = layers.Dense(512, activation='relu')(x)\n","x = layers.Dropout(0.5)(x)\n","x = layers.Dense(1, activation='sigmoid')(x)\n","\n","model = tf.keras.models.Model(base_model.input, x)\n","model.compile(optimizer = tf.keras.optimizers.RMSprop(lr = 0.001),\n","              loss = 'binary_crossentropy', metrics = ['acc'])"],"metadata":{"id":"HM-casF-oAHt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_ds = train_ds.repeat()\n","val_ds = val_ds.repeat()"],"metadata":{"id":"_EiDneOCE-F7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.fit(train_ds, steps_per_epoch=30,\n","          epochs=10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-AVGXOZPpB_E","executionInfo":{"status":"ok","timestamp":1670723451634,"user_tz":480,"elapsed":5504307,"user":{"displayName":"Finn","userId":"01146107018286362364"}},"outputId":"2c878d45-cab9-45b1-9061-abdece1ea7d0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","30/30 [==============================] - 534s 18s/step - loss: -8619.5664 - acc: 0.0900\n","Epoch 2/10\n","30/30 [==============================] - 531s 18s/step - loss: -32805.3398 - acc: 0.0883\n","Epoch 3/10\n","30/30 [==============================] - 509s 17s/step - loss: -61504.1406 - acc: 0.0846\n","Epoch 4/10\n","30/30 [==============================] - 524s 17s/step - loss: -95204.6484 - acc: 0.1067\n","Epoch 5/10\n","30/30 [==============================] - 517s 17s/step - loss: -144039.8906 - acc: 0.0800\n","Epoch 6/10\n","30/30 [==============================] - 520s 17s/step - loss: -194628.5938 - acc: 0.0967\n","Epoch 7/10\n","30/30 [==============================] - 522s 17s/step - loss: -256592.9844 - acc: 0.1017\n","Epoch 8/10\n","30/30 [==============================] - 518s 17s/step - loss: -334113.3750 - acc: 0.1017\n","Epoch 9/10\n","30/30 [==============================] - 529s 18s/step - loss: -409531.0000 - acc: 0.0983\n","Epoch 10/10\n","30/30 [==============================] - 524s 17s/step - loss: -520364.0938 - acc: 0.0933\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f61e62d80d0>"]},"metadata":{},"execution_count":66}]}]}